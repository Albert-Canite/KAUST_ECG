# 报告：MIT-BIH 单导联分段感知模型实现概述

## 模型结构
- **输入**：`(batch, 1, 360)` 的单导联 beat 序列。
- **分段卷积编码器**：P/QRS/T/Global 四组 `Conv1d(1, 4, kernel_size=4, stride=1, padding=0)`，输出通道数均为 4。P/QRS/T 输出长度约 117，Global 输出长度约 357。
- **多 token 池化**：
  - P 段：AvgPool1d 2 块（kernel/stride≈58），得到 2 个 4 维 token。
  - QRS 段：AvgPool1d 3 块（kernel/stride≈39），得到 3 个 4 维 token。
  - T 段：同 P 段，2 个 token。
  - Global 段：时间维全局平均，1 个 token。
  - 最终 8 个 token 堆叠为 `H0`，形状 `(batch, 8, 4)`。
- **Photonic MLP**：`num_mlp_layers`(默认 2，最少 2) 层 `Linear(4,4)+ReLU/tanh`，逐 token 独立映射，保持 `(batch, 8, 4)`。
- **全局汇聚与分类**：token 维平均得到 `h_pool (batch,4)` → 可选 Dropout → `Linear(4,2)` 分类头输出 logits。

## 知识蒸馏
- **Teacher**：一维 ResNet18，输出 `logits_T` 与中间 embedding `feat_T (embedding_dim，可配置)`。
- **Student 输出**：`logits_S` 与 `h_pool` 作为全局特征。
- **蒸馏损失**：
  - 分类交叉熵：`CE(logits_S, y)`。
  - Logit 蒸馏：`KL(softmax(z_T/T), softmax(z_S/T))`，`T=kd_temperature`。
  - 特征蒸馏：`proj_T(feat_T)`、`proj_S(h_pool)` 映射到 `d_kd` 维，L2 归一化后用 MSE 对齐。
  - 总损失：`alpha*CE + beta*KD_logits + gamma*KD_feat`，三者均可配置。
- **训练细节**：Teacher 仅前向、`eval()` 模式，`requires_grad=False`；梯度裁剪 `max_norm=1.0`；Adam 优化器、ReduceLROnPlateau 调度；验证集早停监控组合指标 `F1 - miss_rate - FPR`，`patience=25`、`min_epochs=25`，避免过早停止。

## 数值归一化与约束
- **输入预处理**：每条 beat 减均值、按最大绝对值缩放到 `[-1,1]`，必要时裁剪。
- **受限权重**：`ConstrainedConv1d/ConstrainedLinear` 使用可训练无界参数经 `tanh` 映射到 `[-scale, scale]`，优化器更新原始参数，前向使用映射后的权重/偏置。
- **激活约束**：
  - 若启用 `--use_tanh_activations`，MLP/卷积输出用 tanh，自然落在 `[-1,1]`；
  - 否则在进入受限线性层前调用 `scale_to_unit` 对当前 batch 归一化到 `[-1,1]`。
- **分类头**：保持未约束 logits，直接用于 `CrossEntropyLoss`。

## 数据集与划分
- 训练集记录：`100,101,102,103,104,105,107,108,109,111,112,113,115,117,121,122,123,200,201,202,203,207,209,210,212,213,219,222,223,230,231,232`。
- 泛化集记录：`106,114,116,118,119,124,205,208,214,215,220,221,228,233,234`。
- 数据加载使用 `wfdb` 读取注释，按中心对齐截取 360 点窗口，P/QRS/T 段按 120 点切片。
- `split_dataset` 将训练数据按 80/20 划分训练/验证，batch size 默认 128，可调。

## 超参数与可配置项
- 训练：`--batch_size`，`--lr=1e-3`，`--weight_decay=1e-4`，`--max_epochs`(默认 90)，`--patience=25`，`--min_epochs=25`，`--scheduler_patience=3`。
- 类别不平衡：
  - 类别权重：默认关闭，若开启（`--use_class_weights`）异常类默认 1.0x，可调且受 `--max_class_weight_ratio`（默认 2.0）限制。
  - 采样：默认关闭加权采样 (`--use_weighted_sampler/--no-use-weighted-sampler`)，异常类采样增强倍率 `--sampler_abnormal_boost`（默认 1.0，可调 >1）。
- 模型：`--num_mlp_layers`(≥2)、`--dropout_rate`、`--use_value_constraint`、`--use_tanh_activations`、`--constraint_scale`。
- 蒸馏：`--use_kd`（默认开启，可用 `--no-use-kd` 关闭）、`--teacher_checkpoint`（若未提供且启用 KD，将自动预训练 ResNet18 teacher）`--teacher_auto_train_epochs`（默认 15）、`--teacher_embedding_dim`、`--kd_temperature`、`--kd_d`、`--alpha/beta/gamma`、教师质量阈值 `--teacher_min_f1`、`--teacher_min_sensitivity`，若教师低于阈值会自动禁用 KD 以保护召回率。

## 代码接口与输出
- 前向接口：Student/Teacher 输入 `(batch,1,360)`，Student 输出 `(logits, h_pool)`，Teacher 输出 `(logits_T, feat_T)`。
- 训练脚本保存学生模型到 `saved_models/student_model.pth`，包含 CLI 配置；训练曲线、ROC（验证/泛化）与混淆矩阵 PNG 自动写入 `./artifacts`。

## v1_debug 结果分析与改进
- **现象（用户日志）**：`Val F1≈0.57，miss≈29%`，泛化 miss≈45%，FPR 约 4%。miss 居高，说明正类召回不足。
- **原因分析**：
  1. **类别不平衡**：当前训练集未做重采样，异常类占比低，单靠较小权重提升（原默认 1.3x）不足以提升正类召回。
  2. **教师质量不足**：自动教师仅预训练 5 个 epoch，可能精度/召回偏低，蒸馏信号会“拉低”学生的正类预测倾向，导致 miss 居高。
  3. **采样分布**：无加权采样时，小批次中异常样本稀疏，梯度对正类的强化不足。
- **代码修正**：
  - 提升异常类权重默认值至 2.5，默认启用加权采样并提供 `--sampler_abnormal_boost`（默认 2.0）以放大异常样本出现频次。
  - 自动教师预训练轮数提升至 15，并新增教师质量守卫（F1/TPR 低于阈值则禁用 KD），避免弱教师蒸馏拖低学生召回。
  - 保持早停最低训练轮数与组合指标，配合上述平衡手段，优先降低 miss rate。

## 需求符合性检查
- 分段卷积 + 8 token 池化 + photonic MLP + 均值池化分类流水线已实现并可配置（`models/student.py`）。
- Adam 优化、梯度裁剪、可调 batch_size/epochs/early stopping/LR 调度均在 `train.py` 实现。
- 类别权重、CrossEntropyLoss、KD 的 logit/feature 蒸馏、可切换 KD 流程均实现。
- 数值约束通过 `tanh` 重参数化和输入缩放；输出 logits 未强制约束，符合需求。

## v2_debug 问题分析（基于最新日志）
- **现象**：`Val F1≈0.11，miss≈0%，FPR≈100%`，即模型几乎把所有样本预测为异常；教师自动预训练 `ValLoss≈0.073` 表现正常。
- **数据规模**：Train 42232 / Val 10558 / Generalization 29781，与原始划分一致。
- **原因排查**：
  1. **双重过度放大异常类**：默认同时开启加权采样（异常倍率 2.0）和类别权重（异常 2.5x），在异常占比本就较低的情况下导致正类损失权重/采样概率远大于正常类。为了降低 FN，模型倾向于“全预测异常”，造成 FPR 100%。
  2. **教师正常，KD 信号不是主因**：教师验证损失低、质量守卫通过，学生崩塌主要来自损失权重与采样策略的偏置。
  3. **早停仍保留了崩塌解**：组合指标 `F1 - miss - FPR` 对 FPR=100% 会给出极低得分，但由于训练曲线未明显改善且 patience 已耗尽，提前在劣质解上停止。
- **改进措施（已代码化）**：
  - 下调默认异常类权重至 1.0，并新增 `--max_class_weight_ratio`（默认 2.0）对权重做比值裁剪，防止极端不平衡导致“全异常”预测。
  - 默认关闭采样与类别权重，需手动开启且倍率可控（采样默认 1.0），降低叠加偏置风险。
  - 新增 `--use_class_weights/--no-use-class-weights` 与 `--use_weighted_sampler/--no-use-weighted-sampler` 便于快速排查与调优。
  - 继续保留 F1/miss/FPR 组合早停，并提高 patience/min_epochs，避免短期波动导致的提前停止。

## v3_debug 问题分析（最新日志：FPR=100%，miss=0%，F1≈0.11）
- **现象**：学生依旧“全预测异常”，验证/泛化 TN≈0；教师预训练正常（ValLoss≈0.073）。
- **定位结果**：
  1. **正类偏置叠加仍在**：上轮虽降低权重/采样倍数，但默认依然开启，累积偏置仍将损失重心推向正类，模型在早期就进入“全异常”解。
  2. **缺少在线纠偏**：崩塌出现后，训练循环缺乏自动降权/换采样的防护，导致后续梯度继续固化该解。
- **本轮修复**：
  - 将重加权与重采样默认关闭（需显式开启），并将异常权重默认设为 1.0、权重比值上限 2.0、采样默认倍率 1.0，降低初始偏置。
  - 在训练循环中新增“正类崩塌”自检：若验证集满足 `FPR>95%` 且 `miss<5%`，自动切换为无权重、无采样的 DataLoader，并移除 CE 类别权重，重置早停计数，强制模型重新学习正常类。
  - 延长 patience/min_epochs 至 25，给自检后的再训练留出迭代窗口。
- **后续建议**：
  - 如需提升召回，可先单独调高 `class_weight_abnormal` 或 `sampler_abnormal_boost`，避免权重与采样叠加；观察 FPR，一旦上升可降低倍率或依赖自检。
  - 若仍出现崩塌，可暂时关闭 KD，或降低蒸馏温度，待学生稳定后再恢复 KD。

### v3_debug 补充（最新日志：miss≈50%，FPR≈1%）
- **现象**：最新运行中 FPR 已压到 1% 左右，但 miss 达到 50%+（大量异常被判为正常），Val AUC 较低，召回严重不足。
- **根因排查**：
  1. **失衡反向偏置**：为避免“全异常”崩塌，上一轮默认关闭了类别权重和重采样，结合 MIT-BIH 异常占比偏低，导致模型在 CE 训练中主要优化正常类 → 异常召回大幅下降。
  2. **缺少召回侧自适应**：训练循环只有正类崩塌（FPR>95%）的纠偏逻辑，没有在高 miss、低 FPR 场景下自动提高异常权重或采样，导致模型长期停留在“全正常”侧。
  3. **KD 信号不足以拉回**：教师质量守卫仍可用，但学生在不平衡 CE 下过早收敛为正常预测，蒸馏信号（尤其特征对齐）难以扭转类别偏置。
- **本轮修复**：
  - **温和默认重平衡**：将默认 `class_weight_abnormal` 上调至 1.2，并保持比值上限 2.0；`sampler_abnormal_boost` 设为 1.2，仍默认关闭重采样，但为召回救火预留。
  - **召回自适应**：新增 `--enable_adaptive_reweight`（默认开）。若验证集出现 `miss>30%` 且 `FPR<20%`，自动：
    1) 提升异常类权重（乘以 1.25，并受比值上限约束）；
    2) 若未启用采样，则开启加权采样，并将异常采样倍率提升至 ≥1.5。
    这样在保证 FPR 可控的前提下主动拉升召回。
  - **记录与可控性**：保留崩塌检测（FPR>95%、miss<5%），并允许通过 `--no-enable-adaptive_reweight` 禁用该策略，便于做对照实验。
  - **训练日志可视化**：继续在 `artifacts/` 输出 loss/metrics 曲线、ROC、混淆矩阵，便于观察召回修复效果。

## v4_debug 问题分析（最新日志：早期 miss=100%→FPR=100% 快速跳变）
- **现象**：训练第 2 轮 miss≈100%、FPR≈0（几乎全预测正常），第 3 轮迅速变为 FPR≈100%、miss≈0（几乎全预测异常），随后训练停留在极端输出，说明模型在早期来回崩塌。
- **根因排查**：
  1. **早期重平衡过猛**：虽然降低了默认倍率，但训练一开始就带着类别权重/采样和 KD，同步作用在尚未稳定的随机初始化上，梯度方向极易被放大到单类预测。
  2. **缺少“全正常”侧的防护**：已有“全异常”崩塌检测（FPR>95%，miss<5%），但没有对“全正常”（miss>95%，FPR<5%）的对称防护，导致模型从全正常直接跳到全异常却缺乏缓冲。
  3. **KD 过早介入**：即便教师正常，蒸馏在学生尚未收敛时叠加在失衡 CE 上，会放大偏置并加速崩塌。
- **改进措施（本轮代码已实现）**：
  - **训练暖启动**：前 `--imbalance_warmup_epochs`（默认 5）个 epoch 强制使用无权重、无加权采样的 CE，避免随机初始化阶段被失衡策略放大；之后才切换到温和类别权重/可选采样。
  - **KD 暖启动**：新增 `--kd_warmup_epochs`（默认 5），学生先单独学习，再开启 KD；崩塌检测到异常/正常侧时会临时关闭 KD，允许 CE 先拉回。
  - **双向崩塌防护**：保留“全异常”检测并在触发时关闭重平衡+暂停 KD；新增“全正常”检测（miss>95%、FPR<5%）以恢复类权重、启用采样并暂停 KD，防止长期忽视异常类。
  - **更平滑的自适应**：在高 miss/低 FPR 场景下，异常权重提升因子降至 1.2，并在暖启动结束后才生效，减少剧烈震荡。
- **预期效果**：早期不再左右摇摆，模型先获得稳定的基线再逐步引入重平衡和 KD；若仍出现单侧崩塌，会自动关闭导致偏置的组件（采样/权重/KD）或反向增强异常类，提升召回并控制 FPR。

## v5_debug 问题分析（最新日志：Val F1≈0.38，miss≈11%，FPR≈17%；泛化 miss≈42%）
- **现象总结**：
  - 验证集 F1 仅 0.38，组合 Score≈0.10；召回（1-miss）约 89%，但泛化召回大幅下滑（miss≈42%），FPR 在 13–17% 区间。
  - 日志显示早停在 miss/FPR 尚未明显下降前触发，且 F1 始终偏低，说明决策阈值与模型输出偏置共同拉低了指标。
- **根因排查**：
  1. **固定 0.5 阈值导致指标失真**：训练/早停始终使用 argmax/0.5 阈值，在正负类不平衡时，概率分布偏向正常类，F1 和召回被阈值卡住（FPR 较低但 FN 高），早停过早记录到“假优”解。
  2. **早停基于未调优阈值**：组合指标 `F1 - miss - FPR` 基于 0.5 阈值计算，容易在阈值偏高时低估模型可达性能，提前停止导致未能探索到更优召回/精度的阈值。
  3. **召回与泛化落差**：泛化 miss 远高于验证，说明阈值和类别平衡策略对验证集过拟合；缺少统一的阈值调优并迁移到泛化集。
- **修复措施（本轮代码已实现）**：
  - **阈值搜索与同步评价**：在每个验证阶段对 `[0.05, 0.95]` 范围进行阈值扫描，按 `F1 - miss - FPR` 选出最优阈值；早停评分与日志统一使用该阈值，避免被固定 0.5 阈值束缚召回/F1。
  - **跨集一致性**：训练结束后复用验证最优阈值评估泛化集，并将阈值写入 checkpoint，保证部署/复现实验时决策一致。
  - **可视化与诊断**：生成的 ROC、混淆矩阵已基于最优阈值保存到 `artifacts/`，便于对比调优前后的召回与误报变化。
- **后续建议**：
  - 若 F1 仍低，可适度提高 `class_weight_abnormal`（例如 1.3–1.5）或启用轻量采样（`--use_weighted_sampler`，`--sampler_abnormal_boost≈1.3`），同时观察阈值扫描结果避免 FPR 激增。
  - KD 已有质量守卫和暖启动，如观察到教师弱或学生仍偏正常，可暂时用 `--no-use-kd` 排查蒸馏影响。

## v6_debug 问题分析（最新日志：Val@thr≈0.90 F1≈0.58，miss≈26%，FPR≈5%；泛化 miss≈65%、F1≈0.40）
- **现象总结**：
  - 虽然 FPR 已降至 5% 左右，但 miss 仍高（验证 26%，泛化 65%），导致 F1 和 Score 偏低，ROC/混淆矩阵也显示正类召回不足。
  - 阈值扫描选中了高阈值（≈0.90），进一步压缩了召回；自适应重权重未被触发，训练过程中异常类仍被弱化。
  - 泛化集召回远低于验证，说明当前阈值/重平衡策略在验证集上偏保守且未迁移到更难的泛化分布。
- **根因排查**：
  1. **阈值评分对召回偏置不足**：旧的打分公式 `F1 - miss - FPR` 在 miss≈0.26、FPR≈0.05 时仍给出较高得分，促使阈值向上偏移，抑制召回。
  2. **召回救火触发门槛过高**：触发条件（miss>0.30 且 FPR<0.20，且仅一次）在当前 miss≈0.26 时不会行动，导致权重/采样未随召回低迷自动加强。
  3. **评估阈值搜索步长有限**：仅用等间距网格，可能漏掉概率分布的峰值位置，导致阈值落在保守侧。
- **修复措施（本轮代码已实现）**：
  - **召回偏置打分**：阈值扫描和早停改用 `F1 + sensitivity - 0.5*FPR`，显式奖励召回并在 FPR 可接受时鼓励降低阈值。
  - **更密集的阈值候选**：在 `[0.05, 0.95]` 上叠加概率分布分位点，避免错过模型输出的“拐点”阈值。
  - **可多次触发的召回救火**：新增 `--recall_target_miss`（默认 0.15）、`--adaptive_fpr_cap`（默认 0.25）、`--recall_rescue_limit`（默认 2）。当 miss 超标且 FPR 低时可重复提升异常权重/启用采样，直到达到召回目标或次数上限。
- **后续建议**：
  - 若 miss 仍高，优先提高 `class_weight_abnormal`（1.4–1.6）并打开 `--use_weighted_sampler`（boost 1.3–1.6），观察召回-误报曲线；必要时调低 `--recall_target_miss` 到 0.12。
  - 若 KD 使决策边界偏保守，可用 `--no-use-kd` 或降低 `--beta/--gamma`，再配合新阈值扫描/救火策略评估。

## v7_debug 问题分析（最新日志：Val@thr≈0.90 F1≈0.58，miss≈26%，FPR≈5%；泛化 miss≈65%、F1≈0.40，KD 作用存疑）
- **现象总结**：
  - 即便阈值偏高（0.90），验证 miss 仍达 26%，泛化 miss 高达 65%，F1 受召回拖累明显。
  - KD 未显示明显收益：学生仍偏向预测正常类，召回长期低迷，说明教师信号未被充分吸收或被提前关闭。
  - 类别分布高度不平衡（训练异常占比约 0.3），但加权/采样在早期为了防止崩塌被关闭，后续加权与采样的强度不足以拉升召回。
- **根因排查**：
  1. **阈值筛选缺少“硬约束”**：虽然增加了召回偏置，但没有显式 miss 上限，仍可能选择 miss≈0.26 的高阈值。
  2. **KD 在高 miss 时仍可能介入**：仅在极端 miss 时才关闭 KD，学生在召回低时仍会被教师 logits 牵引，延缓异常类学习。
  3. **自动重平衡力度不够**：仅触发有限次的权重/采样提升，且启动采样依赖手动开关，导致在异常占比较低时召回提升有限。
- **修复措施（本轮代码已实现）**：
  - **阈值搜索加入显式 miss/FPR 约束**：`sweep_thresholds` 先筛选满足 `miss <= threshold_target_miss`（默认 0.12）且 `fpr <= threshold_max_fpr`（默认 0.20）的阈值，再按 recall-强化的得分 `f1 + 1.5*TPR - FPR` 选最优，优先降低漏诊。
  - **KD 召回防护**：新增 `kd_pause_miss`/`kd_resume_miss`，当验证 miss 超过 0.35 自动暂停 KD，降至 0.20 以下再恢复，避免高漏诊阶段被蒸馏信号束缚。
  - **自动采样唤醒**：检测异常占比低于 `auto_sampler_ratio`（默认 0.35）时，暖启动结束后自动启用加权采样；`recall_rescue_limit` 默认提升至 3，召回救火更耐用。
- **后续建议**：
  - 若 miss 仍>0.20，可进一步下调 `threshold_target_miss`（如 0.10）并上调 `sampler_abnormal_boost`（1.5–1.8），观察 FPR 变化。
  - 若教师与学生分布差距大，可暂时关闭 KD 或提高教师质量门槛（`teacher_min_f1`/`teacher_min_sensitivity`），先把学生召回拉高。

## v8_debug 问题分析（最新日志：Val@thr≈0.40 F1≈0.38，miss≈10.6%，FPR≈17.5%；泛化 F1≈0.61，miss≈25.8%，FPR≈12.7%）
- **现象总结**：
  - 阈值搜索偏向 0.40，验证集漏诊已降到 ~10%，但 FPR 仍在 17% 左右，F1 偏低（0.38）。
  - 泛化集 F1 提升到 0.61，但 miss 反弹到 26% 以上，说明决策边界在分布外仍偏保守。
  - 训练曲线显示第 5–6 轮开启加权/采样/KD 时出现 loss 抬升与阈值大幅抖动，之后长时间停留在相近的 F1/miss/FPR 区间，说明重平衡切换过于激进。
- **可能根因**：
  1. **重平衡切换过快**：加权/采样在第 5 轮一次性开启，权重和采样概率突变，引起 loss 爆涨和阈值翻转，随后训练停滞在次优解。
  2. **KD 介入时机与权重跳变叠加**：KD 在同一轮激活，与突增的权重/采样叠加，学生在尚未稳态时同时受 CE+KD 双重扰动，学习方向震荡。
  3. **采样/权重放大但缺少渐进**：`sampler_abnormal_boost` 与异常类权重直接生效，未做平滑过渡；在 FPR 仍然偏高时继续强化异常类，可能压制正常类学习导致 FPR 难以下探。
- **已采取的代码修复（本轮）**：
  - **新增线性 ramp**：在暖启动结束后，引入 `--imbalance_ramp_epochs`（默认 5）对类权重和采样 boost 线性递增；前几轮仍接近无权重/无采样，减少 loss/阈值抖动，逐步过渡到目标重平衡强度。
  - **权重缩放统一管理**：自适应召回救火现在提升一个全局 `class_weight_scale`，由 ramp 平滑施加，并继续受 `--max_class_weight_ratio` 约束，避免瞬时大幅增加异常权重。
  - **采样 boost 平滑更新**：采样启用后按 ramp 插值到目标 boost，并在 boost 变化时重建 DataLoader，避免一次性切换到高倍率采样。
- **剩余关注点/建议**：
  - 若 FPR 仍居高不下，可在 ramp 期间适度降低 `sampler_abnormal_boost`（如 1.1–1.3）或缩短 ramp（2–3 轮）以更快稳定；若 miss 回升则再小幅提升。
  - 如果 KD 在 ramp 期间仍引入震荡，可将 `kd_warmup_epochs` 提升到 8–10，或暂时 `--no-use-kd` 对比；确认教师在当前切分/归一化下有足够召回。
  - 进一步提升模型容量（如增加 `num_mlp_layers` 到 3、开启 dropout=0.1）可尝试，但需监控受限 4 通道设计下的过拟合与推理约束。
